{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8641a15d-e075-4487-8750-55d9f02cc023",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Polyolefin InfraRed Classification - Piped Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99396ad-0ee0-4203-b043-33e9b13c69d4",
   "metadata": {},
   "source": [
    "In connection with: add DOI INFO/LINK HERE\n",
    "\n",
    "This code was predominantly produced by Bradley P. Sutliff, with assistance from Tyler B. Martin, and Debra Audus\n",
    "\n",
    "This notebook is provided in an effort to further open research initiatives and to further the circular economy.\n",
    "\n",
    "Please direct any questions to Bradley.Sutliff@nist.gov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47f3e2-33c8-496c-82c6-15392e3591cc",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4b6dd-9f51-4ced-a46c-347b8749efc9",
   "metadata": {},
   "source": [
    "### Do we want to save the results of this notebook as netcdfs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f2e95-85a7-4d9e-8cfd-faa924d8ea20",
   "metadata": {},
   "source": [
    "This is mostly added to prevent overriding files or generating files unnecesarily when you are \"playing\" with the code. You can always edit this or manually save them later. You will need to eventually save the netcdf file for the following notebooks to work successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7658ae1-c6e7-4739-ae90-480603d8928c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049347f-72b2-4a79-801a-b26063d2f96b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define color schemes and plotting dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d0898b-a76f-4ba7-b7f8-41fcdf4dc0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# set up notebook for plotting nicely\n",
    "%matplotlib inline\n",
    "contxt = \"notebook\"\n",
    "sns.set(context=contxt, style=\"ticks\", palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36abab-26bf-48cb-bdb5-79a83816b05c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set our color palette to match one of our dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35965fc-c9ae-4778-a624-19b06eaf26d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Scripts.misc_funcs as misc\n",
    "\n",
    "cpalette = misc.dict_cBlind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c894b-9c1c-4765-b351-85a51bf12c2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data from our files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a587116-4536-43d5-9eb2-93a54229cc6f",
   "metadata": {},
   "source": [
    "It is assumed that the data and code are set up in the following directory structure.:\n",
    "\n",
    "```\n",
    "Main  \n",
    "  ├ *.ipynb  \n",
    "  ├ Data  \n",
    "  |  ├ SampleInformation.csv  \n",
    "  |  └ NIR  \n",
    "  |    ├ N1476LDPE_1.csv  \n",
    "  |    ├ ...  \n",
    "  |    └ H0009PP_7.csv  \n",
    "  └ Scripts  \n",
    "    ├ *.py  \n",
    "    ├ *.sh  \n",
    "    └ *.ps1  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce0bad-4bc5-44d9-84d8-7042b5f85a2d",
   "metadata": {},
   "source": [
    "First we load the file that has our general sample information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d414e55-a00e-4e76-91dc-6007f0b1130d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Physical State</th>\n",
       "      <th>Color</th>\n",
       "      <th>Recycled</th>\n",
       "      <th>Alternate names</th>\n",
       "      <th>bigSMILES</th>\n",
       "      <th>CAS number</th>\n",
       "      <th>Material Keywords</th>\n",
       "      <th>reference URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Commercial Supplier 4</td>\n",
       "      <td>P0051LLDPE</td>\n",
       "      <td>PE</td>\n",
       "      <td>LLDPE</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>`linear low density polyethylene','LLDPE','pol...</td>\n",
       "      <td>{[][$]CC[$],[$]CC({[$][$]C[$][$]}C)[$][]}</td>\n",
       "      <td>9002-88-4</td>\n",
       "      <td>polyolefins','semicrystalline','copolymer'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Commercial Supplier 3</td>\n",
       "      <td>E0046PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Yes</td>\n",
       "      <td>`polypropylene','PP'</td>\n",
       "      <td>{[][$]CC(C)[$][]}</td>\n",
       "      <td>9003-07-0</td>\n",
       "      <td>polyolefins','semicrystalline','linear','homop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Commercial Supplier 3</td>\n",
       "      <td>E0035PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>PP</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>`polypropylene','PP'</td>\n",
       "      <td>{[][$]CC(C)[$][]}</td>\n",
       "      <td>9003-07-0</td>\n",
       "      <td>polyolefins','semicrystalline','linear','homop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Commercial Supplier 2</td>\n",
       "      <td>C0028PE</td>\n",
       "      <td>PE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`polyethylene', 'PE'</td>\n",
       "      <td>{[][$]CC[$][]}</td>\n",
       "      <td>9002-88-4</td>\n",
       "      <td>polyolefins','semicrystalline','linear','homop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Commercial Supplier 2</td>\n",
       "      <td>C0079PE</td>\n",
       "      <td>PE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`polyethylene', 'PE'</td>\n",
       "      <td>{[][$]CC[$][]}</td>\n",
       "      <td>9002-88-4</td>\n",
       "      <td>polyolefins','semicrystalline','linear','homop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Source      Sample Class1 Class2 Physical State    Color  \\\n",
       "40  Commercial Supplier 4  P0051LLDPE     PE  LLDPE         Pellet  Natural   \n",
       "41  Commercial Supplier 3     E0046PP     PP     PP         Pellet     Gray   \n",
       "42  Commercial Supplier 3     E0035PP     PP     PP         Pellet    Black   \n",
       "43  Commercial Supplier 2     C0028PE     PE    NaN         Pellet  Natural   \n",
       "44  Commercial Supplier 2     C0079PE     PE    NaN         Pellet  Natural   \n",
       "\n",
       "   Recycled                                    Alternate names  \\\n",
       "40      Yes  `linear low density polyethylene','LLDPE','pol...   \n",
       "41      Yes                               `polypropylene','PP'   \n",
       "42      Yes                               `polypropylene','PP'   \n",
       "43      NaN                               `polyethylene', 'PE'   \n",
       "44      NaN                               `polyethylene', 'PE'   \n",
       "\n",
       "                                    bigSMILES CAS number  \\\n",
       "40  {[][$]CC[$],[$]CC({[$][$]C[$][$]}C)[$][]}  9002-88-4   \n",
       "41                          {[][$]CC(C)[$][]}  9003-07-0   \n",
       "42                          {[][$]CC(C)[$][]}  9003-07-0   \n",
       "43                             {[][$]CC[$][]}  9002-88-4   \n",
       "44                             {[][$]CC[$][]}  9002-88-4   \n",
       "\n",
       "                                    Material Keywords reference URL  \n",
       "40         polyolefins','semicrystalline','copolymer'           NaN  \n",
       "41  polyolefins','semicrystalline','linear','homop...           NaN  \n",
       "42  polyolefins','semicrystalline','linear','homop...           NaN  \n",
       "43  polyolefins','semicrystalline','linear','homop...           NaN  \n",
       "44  polyolefins','semicrystalline','linear','homop...           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_info = pd.read_csv('Data/SampleInformation.csv')\n",
    "sample_info.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac8a51-f18f-42c1-9463-3261e76dce1a",
   "metadata": {},
   "source": [
    "Finally, we can use our file to generate a list of the csvs that hold the spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0914bc-15bb-4a62-82d8-995f16320211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "samples = sample_info.Sample\n",
    "replicates = [1, 2, 3, 4, 5, 6, 7]\n",
    "pre_filelist = itertools.product(samples, replicates)\n",
    "filelist = [\n",
    "    f\"Data/NIR/{'_'.join([fs[0], str(fs[1])])}.csv\" for fs in pre_filelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ddd09-57a0-4183-955a-74d010cbeadf",
   "metadata": {},
   "source": [
    "Now we can load in each `*.csv` file from our filelist and add it to an Xarray Dataset. When we load it in, we'll also add all of the information from our other 2 files, and we'll add units where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bad9e5-48e0-4261-93ad-451e18075cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 315/315 [00:01<00:00, 297.84it/s]\n",
      "C:\\Users\\Brad\\miniforge3\\envs\\pirc_demo\\lib\\site-packages\\xarray\\core\\dataset.py:4744: UserWarning: No index created for dimension sample because variable sample is not a coordinate. To create an index for sample, please first call `.set_coords('sample')` on this object.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import xarray as xr\n",
    "\n",
    "ds_list = []\n",
    "for filepath in tqdm(filelist, position=0, leave=True):\n",
    "    sample = filepath.split('/')[-1].split('.')[0]\n",
    "    polymer = sample.split('_')[0]\n",
    "    repeat = sample.split('_')[1].split('.')[0]\n",
    "    s_info = sample_info.loc[sample_info.Sample == polymer, :]\n",
    "\n",
    "    # use pandas csv reader to read in file\n",
    "    dataframe = pd.read_csv(filepath, names=['Wavenumber', 'Intensity'])\n",
    "    # some files span wider wavelengths than others, so this ensures\n",
    "    # we are comparing similar ranges of spectra\n",
    "    dataframe = dataframe.loc[dataframe['Wavenumber'] < 10000, :]\n",
    "\n",
    "    # convert to Xarray Dataset object\n",
    "    dataset = dataframe.set_index('Wavenumber').to_xarray()\n",
    "\n",
    "    # add in extra metadata from filename/filepath\n",
    "    dataset['polymer'] = str(polymer)\n",
    "    dataset['sample'] = str(sample)\n",
    "    dataset['state'] = str(s_info['Physical State'].values[0])\n",
    "    dataset['repeat'] = int(repeat)\n",
    "    dataset['Class1'] = str(s_info['Class1'].values[0])\n",
    "    dataset['Class2'] = str(s_info['Class2'].values[0])\n",
    "    #dataset['Class2_num'] = misc.dict_zord[str(s_info['Class2'].values[0])]\n",
    "    dataset['Color'] = str(s_info['Color'].values[0])\n",
    "\n",
    "    # add units where applicable\n",
    "    dataset['Wavenumber'].attrs = {'units': '1/cm'}\n",
    "    dataset['Intensity'].attrs = {'units': '% Reflectance'}\n",
    "\n",
    "    # define global attributes\n",
    "    dataset.attrs = {'creation_date': datetime.datetime.now().strftime('%Y%m%d'),\n",
    "                     'author': 'Bradley Sutliff',\n",
    "                     'email': 'Bradley.Sutliff@nist.gov',\n",
    "                     'data_collected_by': 'Shailja Goyal'}\n",
    "    # aggregate data into a list\n",
    "    ds_list.append(dataset)\n",
    "\n",
    "ds = xr.concat(ds_list, dim='sample')\n",
    "ds = ds.set_coords(['sample', 'polymer', 'state',\n",
    "                   'Class2', 'Class1', 'repeat',\n",
    "                    'Color'])#, 'Class2_num'])\n",
    "  \n",
    "# also saving a copy of this for later use\n",
    "ds_nopipdims = ds.copy()\n",
    "ds['Intensity'] = (ds.Intensity\n",
    "                     .assign_coords({\"pipeline\": \"none\"})\n",
    "                     .expand_dims(\"pipeline\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19279b9-0a94-43a6-a1f4-dc229968d32d",
   "metadata": {},
   "source": [
    "## Use OneHotEncoder on Class1 and Class2 categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71140292-69ac-4ced-913a-85d926746c86",
   "metadata": {},
   "source": [
    "First separate out the samples that don't have Class 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6119cbb3-8a54-4679-a5dc-b00198300ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_noClass2 = ds.where(ds.Class2=='nan', drop=True)\n",
    "ds = ds.where(ds.Class2!='nan', drop=True)\n",
    "\n",
    "if save_data == True:\n",
    "    ds.to_netcdf('ds_for_ohe.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65189a-ba03-4136-9a3b-47db56df8e30",
   "metadata": {},
   "source": [
    "Now we can encode so that we can use these labels for our classification models later down the road (if we need to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2ee718-5ca8-4862-911e-d223edda2bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe_c1 = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe_c1.fit(ds.Class1.values.reshape(-1,1))\n",
    "ohe_c1_data = ds.Class1.values.reshape(-1,1)\n",
    "ds['Class1_ohe'] = xr.DataArray(\n",
    "    data=ohe_c1.transform(ohe_c1_data),\n",
    "    dims=[\"sample\", \"class_1\"],\n",
    "    coords=dict(\n",
    "        sample=ds.sample.values,\n",
    "        class_1=ohe_c1.categories_[0])\n",
    ")\n",
    "\n",
    "ohe_c2 = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe_c2.fit(ds.Class2.values.reshape(-1,1))\n",
    "\n",
    "ohe_c2_data = ds.Class2.values.reshape(-1,1)\n",
    "ds['Class2_ohe'] = xr.DataArray(\n",
    "    data=ohe_c2.transform(ohe_c2_data),\n",
    "    dims=[\"sample\", \"class_2\"],\n",
    "    coords=dict(\n",
    "        sample=ds.sample.values,\n",
    "        class_2=ohe_c2.categories_[0])\n",
    ")\n",
    "\n",
    "ds=ds.set_coords(['Class1_ohe', 'Class2_ohe'])\n",
    "ohe_dict={'Class1': ohe_c1, 'Class2':ohe_c2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850da3b2-bde0-4549-8dab-1e70749ddf40",
   "metadata": {},
   "source": [
    "## Define our pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a713f0-162a-4f3d-a9e8-d6f3d91ba46c",
   "metadata": {},
   "source": [
    "Now we can start doing what we really want to do: preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f2cdd-defa-4122-9157-cc84ec5f8d58",
   "metadata": {},
   "source": [
    "### Start by defining all of our transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a18751-1eeb-4cf2-9d6a-90cb1067e225",
   "metadata": {},
   "source": [
    "by making these functions into transformers they can be easily called from within a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf581fac-dd52-4a6a-af40-a969612b7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (FunctionTransformer, MinMaxScaler,\n",
    "                                   StandardScaler, Normalizer)\n",
    "from sklearn_xarray import wrap\n",
    "import umap\n",
    "\n",
    "trans_dict = {'None1': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'None2': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'None3': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'None4': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'None5': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'None6': FunctionTransformer(misc.id_func, validate=False),\n",
    "              'MeanCentering':FunctionTransformer(misc.xr_MC, validate=False),\n",
    "              'SNV':FunctionTransformer(misc.xr_SNV, validate=False),\n",
    "              'RNV': FunctionTransformer(misc.xr_RNV, validate=False),\n",
    "              'Detrending': FunctionTransformer(misc.xr_detrend, validate=False),\n",
    "              'SG': FunctionTransformer(misc.xr_SG,\n",
    "                                        kw_args={'window_length':21,\n",
    "                                                 'polyorder':6},\n",
    "                                        validate=False),\n",
    "              'SG1': FunctionTransformer(misc.xr_SG,\n",
    "                                         kw_args={'window_length':21,\n",
    "                                                  'polyorder':6, 'deriv':1},\n",
    "                                         validate=False),\n",
    "              'SG2': FunctionTransformer(misc.xr_SG2,\n",
    "                                         kw_args={'window_length':21,\n",
    "                                                  'polyorder':6},\n",
    "                                         validate=False),\n",
    "              'L1': wrap(Normalizer(norm='l1'), sample_dim='sample'),\n",
    "              'L2': wrap(Normalizer(norm='l2'), sample_dim='sample'),\n",
    "              'MinMaxScaler': wrap(MinMaxScaler(), sample_dim='sample'),\n",
    "              'StandardScaler': wrap(StandardScaler(), sample_dim='sample'),\n",
    "              'PCA': misc.my_PCA(n_components=0.99, min_n_components=5),\n",
    "              'fPCA': misc.my_fPCA(n_components=0.99, min_n_components=5),\n",
    "              'UMAP': wrap(umap.UMAP(n_components=5), sample_dim='sample',\n",
    "                           reshapes='Wavenumber')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7b053-980b-4fc9-ac90-be9789b45c0f",
   "metadata": {},
   "source": [
    "### Now we make the preprocessing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ff00e-2f71-41fe-8e8a-5d18d68d91c8",
   "metadata": {},
   "source": [
    "We can alter these lists if we don't want to run all 1152$^*$ pipelines\n",
    "\n",
    "$^*$1152 pipelines per combination of color and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be46577-3f02-46fd-a671-a918e6e4a731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data selection\n",
    "# l_data_colors = ['Natural', 'NoBlack', 'AllColors'] # Possible color down selection\n",
    "# l_data_state = ['Pellet', 'AllStates'] # Possible physical state down selection\n",
    "l_data_colors = ['AllColors']\n",
    "l_data_state = ['AllStates']\n",
    "\n",
    "# preprocessing steps\n",
    "l_pp_1 = ['None1', 'MeanCentering', 'SNV', 'RNV']\n",
    "l_pp_2 = ['None2','Detrending']\n",
    "l_pp_3 = ['None3', 'SG', 'SG1', 'SG2']\n",
    "l_pp_4 = ['None4', 'L1', 'L2',]                      # Sample normalization\n",
    "l_pp_5 = ['None5', 'MinMaxScaler', 'StandardScaler'] # Feature normalization\n",
    "\n",
    "# data reduction steps\n",
    "l_dr = ['None6', 'PCA', 'fPCA', 'UMAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2abd2e-31d9-449c-ad70-5d8bf7006fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preproc_dict = {}\n",
    "for i in itertools.product(l_pp_1, l_pp_2, l_pp_3,l_pp_4, l_pp_5, l_dr):\n",
    "    pipename = '_'.join(i).strip('_')\n",
    "    pipe = [(j, trans_dict[j]) for j in i]\n",
    "    preproc_dict[pipename] = Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46573290-fe52-4124-aa7a-f8d65f3e2283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AllColors', 'AllStates')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_dsel = list(itertools.product(l_data_colors, l_data_state))\n",
    "l_dsel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978d292-af00-4903-8b30-ace566bfee46",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{Warning! This next cell can easily take an hour or more to run!}}$\n",
    "$\\color{red}{\\text{If you don't want data from all possible combinations, please reduce the lists l_pp_*}}$\n",
    "$\\color{red}{\\text{and l_dr to reduce computation time!}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a09d025-995d-439a-91e2-75e1dd40eb82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [41:18<00:00, 2478.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ds_pp_X = xr.Dataset()\n",
    "ds_pp_Y = xr.Dataset()\n",
    "\n",
    "for dsel in tqdm(l_dsel, position=0, leave=True):\n",
    "     \n",
    "    X, y = misc.data_select(ds, colors=dsel[0], state=dsel[1])\n",
    "\n",
    "    for pipe in list(preproc_dict): # you can also slice this list to speed things up \n",
    "        # print(pipe)\n",
    "        pipe_transformer = preproc_dict[pipe]\n",
    "        pipe_transformer.fit(X)\n",
    "        X_pp = pipe_transformer.transform(X)\n",
    "\n",
    "        ds_pp = xr.DataArray(\n",
    "            data = X_pp,\n",
    "            dims = [\"sample\", \"feature\"],\n",
    "            coords = {\n",
    "                \"sample\": X_pp.sample.values,\n",
    "                \"feature\": np.arange(X_pp.shape[1]),\n",
    "            })\n",
    "\n",
    "        ds_pp_X[f'{dsel[0]}-{dsel[1]}_{pipe}'] = ds_pp\n",
    "        ds_pp_Y[f'{dsel[0]}-{dsel[1]}_{pipe}'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fcf4ca-1dfb-411f-8eb4-6b00f6f88059",
   "metadata": {},
   "source": [
    "Check the number of data variables in X and Y. They should be the same for ease of accessing the data consistently later, but could be as small as `len(l_dsel)` if we wanted to take up less memory/drive space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fa6ed7-48cb-498c-84dd-a63c37ebc91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1152\n",
      "Y: 1152\n"
     ]
    }
   ],
   "source": [
    "print(f'X: {len(ds_pp_X.data_vars)}')\n",
    "print(f'Y: {len(ds_pp_Y.data_vars)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da14a0-05ca-43c6-b18e-9407559ba7d3",
   "metadata": {},
   "source": [
    "## Do we want to save the preprocessed data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93db079-84c1-4f43-88ea-31ae971782eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_data=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c2dc6f-4254-4d4e-8f7a-0adc1b956e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240709135516\n"
     ]
    }
   ],
   "source": [
    "if save_data == True:\n",
    "    from datetime import datetime \n",
    "    #check for location to save data\n",
    "    import os\n",
    "    newpath = r'NetCDFs/'\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    date = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "    print(date)\n",
    "    ds_pp_X.to_netcdf(f'NetCDFs/{date}_preprocessed_X_example.nc')\n",
    "    ds_pp_Y.to_netcdf(f'NetCDFs/{date}_preprocessed_Y_example.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d72ea06f-3129-406c-88bb-8279788bba4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('netCDF_date.txt', 'w') as file:\n",
    "    file.write(f'{date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75f1ccf8-37f3-447d-895d-7cc508d85a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca76b7-8830-4d1b-8b28-470eb200a046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pirc_demo]",
   "language": "python",
   "name": "conda-env-pirc_demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
